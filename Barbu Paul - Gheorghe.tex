\documentclass[12pt,a4paper,titlepage]{report}

\usepackage{times}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}

\usepackage{setspace}
\onehalfspacing

\usepackage[hidelinks]{hyperref}

\usepackage{graphicx}

\usepackage{minted}
%TODO: remove red box on parser error

\setminted{baselinestretch=1,fontsize=\footnotesize}

\usepackage{caption}

\usepackage{algorithm} %[plain] ?
\usepackage{algpseudocode}
\makeatletter
\renewcommand*{\ALG@name}{Pseudocode}
\makeatother

\usepackage{multirow}

% avoid floats moving outside the sections
\usepackage[section]{placeins}

% margini de 1 inch peste tot
\usepackage[margin=1in]{geometry}

\usepackage{amsmath}

%\usepackage{draftwatermark}
%\SetWatermarkText{Draft}
%\SetWatermarkScale{1}

\author{Barbu Paul - Gheorghe}

%TODO: coperta
%TODO: plan tematic?

\begin{document}

\begin{titlepage}
{
	\centering
	\textbf{"Lucian Blaga" University of Sibiu – Romania} \\
}

{
	\centering
		\textbf{Faculty of Engineering} \\
}

{
	\centering
		\textbf{Master program:} Advanced Computing Systems \\
}


\vfill

{
	\centering
	\Large
	\textbf{DISSERTATION} \\
}

{
	\centering
	\Large
	Forecasting electricity consumption and production using ARIMA time series models \\
}

\vfill

{
	\centering
		\textbf{Graduate:} Barbu Paul - Gheorghe\\
		\textbf{Scientific coordinator:} Conf. dr. ing. Árpád GELLÉRT \\
}

\vfill

{
	\centering
	2019 \\
}
\end{titlepage}

\tableofcontents
\newpage

\subsection*{Abstract}

The current dissertation thesis aims to develop an understanding of time series forecasting principles, with an emphasis on the Auto Regressive Integrated Moving Average algorithm (or ARIMA for short), in the energy consumption field. The aim is also to develop a software implementation that uses the ARIMA model in order to easily forecast a given time series and to be able to analyze the results and decide if the chosen model is properly predicting the data or not.

Electric energy consumption is something that we take for granted. Even if actively consuming electricity while using a desktop computer, by lightning our rooms or by passively consuming electric energy while our smart-phones are in standby mode it is safe to say that we use electric energy all the time. That is, without even considering industrial use-cases, where up times of 24 hours 7 days a week are expected from most factories. As such, I consider that electricity is a much needed depletable resource and, as is the case with any such resource that we have to generate, we also have to know how we use it in order to better manage it.

Considering the fact that electricity domestic consumption has been steadily increasing (with the exception of 2009, maybe because of the financial crisis and other hard to explain factors) \cite{enerdata} for the world as a whole, it is past time to take note of our consumption patterns and start adapting them in order to reduce the footprint we leave on the medium and to minimize the waste of electrical energy, which cannot be reliably stored in high amounts.

Hence this work focuses on finding the patterns in the electrical energy consumption and predicting them using ARIMA models, with the hopes that being able to tell how consumers will use the energy in the near future, home owners, companies and governments may optimize their behavior and the import and export of electricity.

This work will focus on a single set of data for making the forecasts about energy consumption, although the principles, models and the way of thinking presented herein should be general enough to be applicable for other time-series data sets that are out there. What will change is, of course, the parameters given to the used ARIMA models and the interpretation of the results.

The Auto Regressive Integrated Moving Average algorithm was chosen to make the predictions since it is a combination of several other models and can generalize them, covering a wide range of possibilities through its parameters. Being a very general algorithm for time-series predictions it is also widely used, not only for electric energy consumption \cite{bouzerdoum}, but also for finance and socio-political data \cite{fpp2}.

This work will present how the ARIMA models work and the statistical machinery around them from my experience while forecasting one data set, comprised of five different time-series. The data set has been used in other works as well, one of which was done here at "Lucian Blaga" University of Sibiu, in the same department. The paper, called "Loads management based on Photovoltaic and Energy Storage System" \cite{feilmeier}, studies the very same idea that I set out to study in this work, the difference being that the author uses artificial neural networks to model and predict the given data. So given the fact that this data has already been analyzed, we have the opportunity for comparing the performance of Artificial Neural Networks, computed by Stefan Feilmeier, with the performance of ARIMA, computed in this paper by myself.

The five time-series in the dataset are all gathered at the same time, starting with the beginning of year 2015 on 1st of January. Each data point represents the current Watt usage of a home, gathered every five minutes during a period of five months, so until the month of May 2015 (inclusive), tallying up to around 150 days of data, each consisting of 288 individual sampling points. Although there is plenty of data to work with, only three of the time-series represent actual consumption, on each of the three phases of three phase current (Ph1, Ph2 and Ph3). The other two time-series (namely: PV1 and PV2) are actually the number of Watts produced by two photo-voltaic panels mounted on the same house.
Because of the nature of the data, there should be no difference in forecasting the two groups of time-series, it doesn't matter if the energy is gathered or consumed, the prediction work-flow and mechanisms used in this paper should remain generally applicable, only the semantics of the conclusions will change, instead of saying "I predict there will be consumed X Watts over the next period of time", one would instead say: "I predict there will be generated X Watts of energy over the next period of time".

The current state of the time-series algorithms and available statistical tools in the programming communities have pushed me to use the R programming language \footnote{\url{https://www.r-project.org/}} in order to carry out the task of this dissertation paper, because R seems to be the best and among the most used \cite{Rdesign} choice for interactive analysis of data and statistical studies, having over 13000 (thirteen thousand) packages available online\footnote{At the beginning of 2019, according to: \url{https://cran.r-project.org/web/packages/}}, packages that can be used to carry out different tasks, from string manipulation and XML parsing, to forecasting time-series data.

So this paper aims at creating a functional software implementation using the R programming language and its rich ecosystem in statistical tools (of which I use ARIMA models) for forecasting the electrical energy consumption for a household over a predetermined period of time. By the end of the paper the reader will conclude that the goal has been successfully achieved and a variation on the ARIMA algorithm is indeed suited for forecasting electrical energy demand time-series such as the ones used here. The results are favorable compared to those produced by the ANN method, but not by much compared to some benchmark algorithms which are much simpler in terms of mathematical complexity and shorter in term of both implementation and running time.

\newpage
\chapter{Theoretical considerations}
\section{Introduction and etymology}

The verb "to forecast" means "to predict" or "to estimate" a future event or trend \cite{oxfordForecast}, when used as a noun it refers to the results of the verb, the data that has been estimated or predicted.

This paper has set as its goal to predict the electrical energy consumption and production of a modern house using the Auto Regressive Integrated Moving Average model, while at the same time understanding and presenting the algorithm and its constituent parts.

The underlaying problem that pushed me to choose this kind of a project is the fact that electrical energy cannot be stored in high amounts and, as a consequence, countries and governments need to understand the patterns of consumption and production of their residents in order to optimize the import and export of electrical energy. Through such optimizations the price of electricity could be reduced, which is a benefit to the domestic consumer.

We also have to keep in mind that there is an increase in electrical energy consumption worldwide, according to Enerdata \cite{enerdata} and their plot of electricity demand which can be seen in figure \ref{energytrend}. All the while there is an increasing interest for green energy, while forecasting in itself doesn't help on this front of the problem, it can help to predict which households might be suited for photo voltaic panels installation in order to further reduce the carbon dioxide footprint. 

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{denergytrend}
    \caption{Electrical Energy Consumption Trend}
    \label{energytrend}
\end{figure}

In what follows, apart from the word "forecasting" I will also use the words "model" and "algorithm". Most of the time I will use the two words interchangeably, for example "ARIMA model" or "ARIMA algorithm", but, if being pedantic is desired, their meaning is different since "model" refers to the mathematical or statistical model that is the basis for the later-developed algorithm. We can look at it this way: the model is the building block of the algorithm. The algorithm on the other hand being the series of steps taken to solve a particular problem.

In the end I'd like to be able to state that for a given time frame in the future a household will consume or generate a certain amount of energy with 80\% or even 95\% confidence.

\section{Structure of the dissertation}

The paper is arranged in two chapters, the present one, which aims to explain the theoretical concepts behind time-series forecasting using ARIMA and to give insights to the statistical concepts underlaying the decisions taken throughout the research phase.
This chapter should present the current state of the domain and the advances in forecasting time-series data, each concept occupying its own section. A cursory look at the R programming language and its ecosystem of statistical tools and Integrated Development Environments (or in short: IDEs) will be provided. Then an in depth explanation will be provided to each and every one of the main concepts involved in the process of forecasting electrical energy demand using the ARIMA model.

The second chapter shall disseminate the actual research work flow that I applied in solving the problem of electricity demand forecasting with ARIMA. The concepts explained in this second chapter are using the theoretical basis introduced in the first chapter.
Here I will present the results of my work and compare the ARIMA algorithm to previous work done on the same data but by using Artificial Neural Networks (or in short ANNs) by Stefan Feilmeier.

The second chapter will also shine some light on why R is one of the best tools to use in such a context, where easily accessible statistical instruments are of utmost importance. This will be accomplished by showing and explaining the key code snippets of the research, while to full source code will be available on the accompanying CD.

\section{State of the art in forecasting}

Considering the fact that energy production and consumption is so widespread it is very hard to quantify the exact state of the forecasting methods and tools used by the big electricity providers, mainly because of their variety, but also because of the trade secret nature with which such methods are treated. Basically being able to predict the future in any given domain, not only electricity production and consumption, also means that you can use that information to your advantage, hence the secret nature of the business. Still, saying that the methods presented herein are able to predict the future is not very accurate, what we can do is: we can analyze the past and from that data make inferences about the future, hypothesize about it with some degree of confidence.

Taking a bird's eye view of the problem, it is no different than what we are used to in weather forecasts. We can say for example with 60\% confidence that in the next several hours it will rain. This statement is bases on previous data that is at the meteorologists' disposal, data such as past rainfall quantities for the current season or even day and hour, the direction of the wind, the amount of clouds and the difference in air pressure in the area that they will forecast rain for.

Similarly, for electrical energy demand prediction we can have models that take into account several predictor variables, such as the time of day, the temperature, the season and maybe other social elements.
\begin{itemize}
    \item time of day - is important in prediction because in the case of electrical energy consumption we could imagine a scenario where the consumption would be highest in the morning when everyone gets ready for work or school and then decrease a bit, only to increase back again during the evenings when everybody returns home. The same logic applies to electricity production by photo-voltaic panels, their peak would be at noon, when the sun shies brightest and the light's angle of incidence is the widest.
    \item the outside temperature is also important in countries that mostly use electrical based heating and cooling. In the summer months, when it's hot outside, electrical energy will be used to power air conditioning units, while in the winter months when it's cold outside, energy will be used for heating our homes.
    \item the season is the common element that influences both of the above. We don't expect photo-voltaic panels to be of much use even during noon hours in an winter month (because there is a high chance they will be covered with snow) or on rainy days when the sky is overcast.
\end{itemize}

In this paper we will also inspect this multiple regression route, where we will use several external regressors as predictors of future energy consumption or production, but also several basic forecasting methods, such as the naive method, seasonal naive, and the mean method as baselines for measuring the prediction accuracy when using more complex models such as ARIMA, Seasonal ARIMA (short: SARIMA) or (S)ARIMAX (ARIMA with external regressors and possibly seasonality).

\subsection{ARIMA}
The main model that this dissertation work started around is called ARIMA, short for Auto Regressive Integrated Moving Average.
But, as we will later see, diverged towards more complicated variations of it.

The original ARIMA model was introduced in 1970, but it is still widely used even today, half a century in the future.

The book, which describes this model was written by George E. P. Box and Gwilym M. Jenkins, considered the founding fathers of modern time-series analysis. The book is now revised and at its fifth revision \cite{boxjenkins}, revised by Gregory C. Reinsel and Box's doctoral student Greta M. Ljung.

These names might sound familiar from such concepts as "Box-Cox transformation" or "Ljung-Box test", which we will explore later on as well since they are related to the field I'm interested in the thesis.

What Box and Jenkins have proposed in their 1970 book is that they could model any time-series pattern by the equation \ref{boxjenkinsequation}.
\begin{equation}
\label{boxjenkinsequation}
y'_{t} = c + \phi_{1}y'_{t-1} + \cdots + \phi_{p}y'_{t-p} + \theta_{1}\varepsilon_{t-1} + \cdots + \theta_{q}\varepsilon_{t-q} + \varepsilon_{t}
\end{equation}

The left hand side of the equation represents the predicted (and differenced) value of $ y $ and the right hand side represents the "predictor" variables, where the predictors are made up of:

\begin{itemize}
    \item $ c $: a constant, which may or may not be included, depending on the shape of the data
    \item $ \phi_{p}y'_{t-p} $: one or more Auto Regressive terms (AR), their number is defined by the $ p $ parameter of the ARIMA model and are weighted by the $ \phi_{p} $ coefficients which are computed during the fitting phase of the ARIMA model
    \item $ \theta_{q}\varepsilon_{t-q} $: one or more Moving Average terms (MA), again, their number is defined by the $ q $ parameter of the ARIMA model and are weighted by the $ \theta_{q} $ coefficients which are computed during the fitting phase of the ARIMA model, similarly to the AR coefficients $ \phi_{p} $
    \item $ y'_{t} $: is the differenced series (once or several times), the number of differences is given by the $ d $ parameter of the model.
    \item $ \varepsilon $: represent error terms which are independent, identically distributed with zero mean, which basically means they are random errors.
\end{itemize}

This is the basic idea of the ARIMA model, and together with its parameters is written as: $ ARIMA(p, d, q) $ \cite{fpp2nonseasonalarima}, where:
\begin{itemize}
    \item $ p $: the order of the autoregressive part
    \item $ d $: the number of non-seasonal differences applied
    \item $ q $: the order of the moving average part
\end{itemize}

So to sum the model up in a phrase, I can say that ARIMA represents future values in terms of several past values and errors, all adjusted by coefficients to match the past data as best as possible.

\subsection{SARIMA}

The model previously presented does not take into consideration seasonal data. One may observe seasonal data when one is analyzing a longer time series, such as several months or maybe several years, where the phenomenon has time to repeat itself.

Seasonal data in statistics is the equivalent of periodic functions in mathematics. Basically in mathematics we think about the function's values repeating themselves after one period. In statistics and time series analysis we think about events that repeat themselves constantly each season, hence the term "seasonality". Birthdays, Christmas and weekends are well known seasonal events.

In order to model such time-series accurately, one has to be able to capture the influence of the seasonal events contained in the seasonal data, this is accomplished by adding four more parameters to the original ARIMA model, leading to: $ ARIMA(p, d, q)(P, D, Q)[m] $ \cite{fpp2seasonalarima}. The equation \ref{sarimaequation} represents such a model \cite{automatictimeseriesforecasting}.

\begin{equation}
\label{sarimaequation}
\begin{split}
y'_{t} = c + & \phi_{1}y'_{t-1} + \cdots + \phi_{p}y'_{t-p} \\
           + & \Phi_{1}y'_{t-m-1} + \cdots + \Phi_{P}y'_{t-m-P} \\
           + & \theta_{1}\varepsilon_{t-1} + \cdots + \theta_{q}\varepsilon_{t-q} + \varepsilon_{t} \\
           + & \Theta_{1}\varepsilon_{t-m-1} + \cdots + \Theta_{Q}\varepsilon_{t-m-Q} + \varepsilon_{t-m}
\end{split}
\end{equation}

Where:

\begin{itemize}
    \item $ p $, $ d $, $ q $: keep their original, non-seasonal, meaning
    \item $ P $, $ D $, $ Q $: are the equivalent of their lower-case version, but they define the orders of the autoregressive, differencing and moving average for the seasonal part of the data.
    \item $ \Phi_{P}y'_{t-m-P} $: one or more Seasonal Auto Regressive terms (SAR), their number is defined by the $ P $ parameter of the SARIMA model and are weighted by the $ \Phi_{P} $ coefficients which are computed during the fitting phase of the SARIMA model
    \item $ \Theta_{Q}\varepsilon_{t-m-Q} $: one or more Seasonal Moving Average terms (SMA), again, their number is defined by the $ Q $ parameter of the ARIMA model and are weighted by the $ \Theta_{Q} $ coefficients which are computed during the fitting phase of the SARIMA model, similarly to the SAR coefficients $ \Phi_{P} $
    \item $ m $: this parameter is in fact a pseudo one, usually it cannot vary, being fixed to the seasonal period of the data. For example a birthday occurs yearly, weekends occur weekly, and the examples may continue for monthly events and even quarterly for business and data belonging to the economics domain.
\end{itemize}

The $ ARIMA(p, d, q)(P, D, Q)[m] $ model is also known as SARIMA \cite{berkleysarimamodels}.

\subsection{(S)ARIMAX}
The ARIMA and Seasonal ARIMA models include information only about the time-series itself in the model. No other external information can be used.

When forecasting electrical energy consumption it is important to be able to adjust the predictions according to the time of day for example. Since the sun is shining the brightest at noon, it is safe to say that the most electrical energy will be generated around that time by the photo voltaic panels installed on one's house. For consumption estimation it would be ideal to have also temperature data, in the hot days we would use energy to cool our houses and in the cold days energy is used to heat them. If the temperature data is not available (we should also note that it should be available in the future, when we need to make our electrical energy consumption predictions) then it might be sufficient to use the calendar month for which we should forecast the electricity demand and from there we can infer if it is a summer month or a winter month, hence having a general sense of the temperature.

The (S)ARIMAX algorithm allows us to incorporate such data into the analysis. The short form comes from the longer one: Seasonal ARIMA with eXternal regressors, the "X", coming from "external regressors".

This model is in fact a multiple regression model with time series error terms \cite{boxjenkins}, which are being fit with ARIMA.

The general mathematical form for such a model (without seasonal parts, for ease of reading and in order to avoid listing a cluttered equation) is given in equation \ref{arimaxequation} \cite{nauarimax}.

\begin{equation}
y'_{t} = c + \beta x'_{t} + \phi_{1}y'_{t-1} + \cdots + \phi_{p}y'_{t-p} + \theta_{1}\varepsilon_{t-1} + \cdots + \theta_{q}\varepsilon_{t-q} + \varepsilon_{t} 
\label{arimaxequation}
\end{equation}

Or it may be written as in equation \ref{arimaxequationfpp2} \cite{hyndmanarimax} \cite{fpp2arimax}.

\begin{equation}
\begin{split}
y'_{t} &= \beta x'_{t} + n'_{t} \\
n'_{t} &= \phi_{1} n'_{t-1} + \cdots + \phi_{p} n'_{t-p} + \theta_{1} \varepsilon_{t-1} + \cdots + \theta_{q} \varepsilon_{t-q} + \varepsilon_{t}
\end{split}
\label{arimaxequationfpp2}
\end{equation}

Equation \ref{arimaxequationfpp2} is easier to interpret as a regression with ARIMA errors, since we rewrite the right hand side part of equation \ref{arimaxequation} as a different term:
\begin{itemize}
    \item $ y'_{t} $: is the forecast time series, optionally differenced
    \item $ x'_{t} $: is the external regressors time series, such as temperatures, hours of day, days of week, months, etc.
    \item $ \beta $: is the coefficient applied to the external regressors time series
    \item $ n'_{t} $: is an $ ARIMA(p, d, q) $ error time series
    \item $ \phi $, $ \theta $, $ \varepsilon $, $ p $, $ d $, and $ q $: keep their original meanings
\end{itemize}

Rob J. Hyndman and George Athanasopoulos list several useful predictors \cite{fpp2usefulpredictors} to be used for the $ x_{t} $ term in the regression equation in their book Forecasting: Principles and Practice \cite{fpp2}. Among them, they list:

\begin{itemize}
    \item trend, or time: some time-series are highly correlated with time, for example the increasing value of good wine or musical instruments are highly correlated with the passing of time
    \item dummy variables: electrical energy consumption might be influenced by public events. These events may attract other people in an area and I expect them to be accommodated overnight, one might predict an increase in electricity demand during the period of the event. These events may be modeled as dummy variables, only influencing the analyzed data around the time they take place. 
    \item seasonal dummy variables: household electrical energy consumption might be influenced by public holidays as well, since most people do not have to work on public holidays we might expect an increase in electricity demand during those holidays Easter, Christmas, National Day, etc. when people are more prone to staying at home. These events may be modeled as seasonal dummy variables, as well. They only influence the analyzed data around the time they take place, but they do it periodically, in the case of may enumeration, yearly. We could just as well imagine scenarios where the seasonality is weekly, or quarterly.
\end{itemize}

The authors of the aforementioned book, also note that one need not use seasonal dummies when the seasonal period is very long. Instead one can use terms of the Fourier series \cite{fpp2dhr} to model longer and more complex seasonality. The intuitive explanation given to this fact is the the Fourier terms can smooth a little bit the predicted time series and at the same time, take the shape of it, akin to using the Fourier series in signal processing or data compression.

All of the presented variation on the ARIMA algorithm will be used in my research for the best model that fits the data and predicts it most accurately.

\subsection{Other state of the art models}

Up to this point I have exposed only ARIMA models that can be applied to time-series. There are other models out there, not specific to time-series, but very general and can be applied to such data as well.

One widely used method for prediction purposes are the Markov Models, as shown in \cite{markovpersonmovement}, they can be leveraged to successfully predict the movement of one person in several rooms.

Then there are Artificial Neural Networks as researched by Stefan Feilmeier in \cite{feilmeier}, where he tackles the same subject area that I am interested in in this paper, namely predicting the electrical energy consumption and production of a household over a period of time.

There are other authors such as M. Bouzerdoum et al that investigated a hybrid model (SARIMA–SVM) for short-term power forecasting
of a small-scale grid-connected photo voltaic plant \cite{bouzerdoum}. Their research uses the SARIMA algorithm, whose results are further refined by by a Support Vector Machine model.

Pedro and Coimbra, in 2012, have analyzed five different models: Persistent, ARIMA, k Nearest Neighbors (or shorter: kNN), ANNs and Genetic Algorithm optimized ANNs. They reported the best results with ANNs and Genetic Algorithm (or in short form: GA) optimized ANNs \cite{pedrocoimbra}.

Ding and others have proposed in 2001 an ANN system with forecasts a full day into the future the power output of a photo voltaic plant. They report that improvements can be made if the day of the forecast is selected to match weather data \cite{ding2011ann}. This approach of selecting the day based on weather data is similar to using dummies in ARIMAX models, we would have one set of dummies for sunny days and another one for cloudy days.

The scientific literature presents itself with quite a few options that one can use to efficiently and accurately predict electrical energy consumption and production, ranging from Artificial Neural Networks and k-Nearest Neighbors to Auto Regressive Integrated Moving Average (including its variations with seasonality and exogenous variables).

\subsection{Benchmarks methods}
Up to this point in the paper I have only presented complicated and advanced methods (both from a mathematical standpoint and from an implementation point of view). What will follow in this subsection is the brief description of some benchmark models that I will use to quantify the improvements of my own research with ARIMA models.
Complex models such as ARIMA and ANNs might be necessary to capture all the fine details and intricacies of real life data and, at the same time, be able to properly and accurately forecast several data points into the future.

Still, I also need to establish some baseline and start my analysis from there. After running the benchmark methods and establishing the baseline errors in prediction, I will be able to tell by how much the ARIMA models have improved.

Although not state of the art, these methods are the basic building blocks of other, more complex, methods and I prefer to include them here, since they are, too, related to methods of making predictions. The biggest argument for including them here is that we, as humans, use these methods intuitively by the so called "System 1" when taking decisions, as noted by the Nobel prize winner, Daniel Kahneman \cite{kahneman2011thinking}.

The three benchmark methods \cite{fpp2simplemethods} that I used to create baseline predictions are:
\begin{enumerate}
    \item naive: use the last available data point as a forecast for the next data point. The equivalent equation would be: \[ y_{t+1} = y_{t} \]
    This method is also known as the "random walk model" and can be compared to answering the question "What will tomorrow be like?" with: "Tomorrow will be a lot like today" since we only have information about the past and present and because we infer that the near future cannot change that drastically, we infer that it will be the same as the present.
    \item seasonally naive: similarly to the naive method, this method will forecast the next value to be exactly the same value from the previous season. Mathematically this is: \[ y_{t+1} = y_{t+1-m} \] 
    Intuitively, if $ m $ (the seasonal period) is one week, is like answering the question "What will tomorrow (Wednesday) be like?" with: "Tomorrow (Wednesday) will be exactly like the previous week's Wednesday", there being no reason to believe that things will change dramatically from one week to the other.
    \item average: finally, the average method takes all known past values, averages them together and predicts the future values using that result. Mathematically: \[ y_{t+1} = \frac{y_{1} + \cdots + y_{t}}{T} \]
    Where $ T $ is the number of previous observations.
\end{enumerate}

\section{The choice of programming technologies}

In this section I will talk more about the technology I chose to pursue this research and the rationale behind this decision.
While the choice now may seem very obvious, I shall not fall victim to hindsight bias \cite{hindsightbias} and believe that I should have chosen it sooner and faster.

This research was preceded by a semester project \footnote{Which I made publicly available under the MIT license at: \url{https://github.com/paulbarbu/arima-energy-prediction}} during the first year of the master's degree (fall of 2017) and for that project, the tool of choice, unfortunately, was Java. The reason for that is the fact that everybody at the university understands Java, since it is taught and used in some of the bachelor courses. The project's goal was to use ARIMA to predict energy consumption on the same data that I will use for this research. The results of that project were, at best, modest. Much of the outcome is due to the fact that Java, as far as I know, lacks proper statistical analysis tools, so the ecosystem for the needed instruments is rather poor. Java has a very rich ecosystem, but apparently it lacks in the area of statistical tools. Of course the ARIMA libraries found and used by myself were also of low quality, at least from the point of view of the documentation. They were laking the instructions on how to use them, regardless of their internal quality, if there is no user manual, the internal quality has no value since it cannot be taken advantage of.

Another reason for the poor outcome of the project is based on Java's compilable nature. In a development session with Java one has to write code, compile it, run the application and only then see the results. Notice how the writing of the code and running of the code phases are separated by another "compilation" step. The problem with this intermediary step is the fact that it is a mental hurdle. The work flow with Java is not continuous at all, making small adjustments, regardless of their impact, means that there will be empty time slots taken by the compilation step until the results of the adjustments will be observable.

This behavior is in contrast with the Read-Eval-Print-Loop (or REPL for short) that LISP-like languages have adopted and is specific of newer scripting programming languages such as Python and R \cite{hey2014computing}. In a REPL environment, the programmer can write single lines of code, without ever having to write the full program, the main function and other boilerplate code. Individual lines of code may be evaluated and their results inspected at once, without having to interrupt the programmer's work flow. This kind of programming enables quick exploration of ideas and rapid development of proof-of-concept applications.

This is the main reason for which, during the semester project I explored programming tools such as the Jupyter Notebook \footnote{\url{https://jupyter.org/}} for Python\footnote{\url{https://www.python.org/}} and RStudio\footnote{\url{https://www.rstudio.com/}} for R. While the former tool is not a complete Integrated Development Environment (or IDE for short), it has all the necessary features to allow for decent work to be carried through, the latter tool is indeed a complete IDE. Both tools center around the idea that the programming languages they are designed for are scripting programming languages and allow the programmer access to an interactive medium, where the results of running even individual lines of code are immediately available. A huge advantage of this is that the tools even produce instant plots of the data, allowing quick, graphical, visualization of results. This is the biggest advantage of such programming environments. This superiority is nicely exposed by Bret Victor in his 2012 talk "Inventing on Principle" \footnote{\url{https://vimeo.com/36579366}}, where small changes and even big ones have an immediate outcome and are visible right away.

\subsection{R}

After having some experience with both R and Python on the tooling side, I chose to use R as a programming language for the current research because it was specifically designed for statisticians and their needs. Having higher chances to include the needed algorithms and methods used for making time-series predictions. The biggest advantage of R was the "forecast" package \cite{rforecastpackage} \cite{automatictimeseriesforecasting} which provides an implementation for fitting of ARIMA models and their seasonal and external regressors variations.

Another favorable argument for choosing R, is the RStudio IDE, which is easily installable and once can start working right away.
A screen shot of RStudio's main window can be seen in figure \ref{rstudiomainwindow}. The upper left corner is reserved for writing full programs, of which, one or several instructions can be run separately into the console in the lower left corner. The results of such individual executions will also be displayed right away into the console. If graphical representation such as plots are created, they will show up on the lower right corner of the window, without having to open the files from the file system or to interrupt one's work flow. The documentation of the used functions can also be accessed in the lower right corner, with the same philosophy in mind, continuous work flow and less task and context switching for the programmer. Finally, the upper right corner of the window is the place where the programmer may access the history of his executions and the variables in the current environment, all in real time.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{drstudio-windows}
    \caption{RStudio's main window, courtesy of \url{https://www.rstudio.com}}
    \label{rstudiomainwindow}
\end{figure}

Clearly these are all advantages. Another advantage is that the code is not that different from what a Java or C programmer is used to writing, despite the language being very different in philosophy. A short snippet of R code that defines the product function can be seen in listing \ref{exampleRcode} and an example of filtering and substitution can be seen in listing \ref{exampleRsubstitution}, this example is particularly meaningful for R's capability to manipulate data sets (in the form of vectors, lists and data frames) in very concise ways.

\begin{listing}[h]
\begin{minted}{R}
f <- function(x, y) {
  r <- x * y
  return(r)
}
\end{minted}

\caption{Simple function definition in R}
\label{exampleRcode}
\end{listing}

\begin{listing}[h]
    \begin{minted}{R}
    # substitute negative values with 0
    values[values < 0] <- 0
    \end{minted}
    
    \caption{Example of value substitution and filtering in R}
    \label{exampleRsubstitution}
\end{listing}

The two down sides that I have found while working with R are the following:
\begin{enumerate}
    \item R's lists and vectors start at index 1, most other programming languages start the indexing at 0. While this is no technical shortcoming, it is a different mindset that one has to adapt to.
    \item the preferred assignment operator in R is "<-". Most of the time, while valid and totally interchangeable for simple assignments, the usage of "=" is discouraged. The usage of "=" for assigning default values for function parameters is preferable however \cite{RassignOps}.
\end{enumerate}

The multitude of tutorials and learning resources available on R online are making the programmer's life easier and make for a sweeter learning curve as the language is really popular in scientific internet circles it is easy to find answers to problems that arise while working with it.

\subsection{R alternatives}
As mentioned before, there are other alternatives to R, such as Python. While recently Python has seen an increase in usage \cite{pythongrowth}, its usefulness in scientific and statistical computing is still in development, and according to the cited article some developers switch from Python to R for data intensive tasks.

Both Python and R have the advantage of being fully open-source, that means that they are free for individual and commercial use. This fact also stands true for their big ecosystems of packages and libraries. There are also paid alternatives such as SAS \footnote{\url{https://www.sas.com/en_us/software/stat.html}} and SPSS \footnote{\url{https://www.ibm.com/analytics/spss-statistics-software}}. SAS, from the Graphical User Interface (or GUI, for short) point of view is very similar to RStudio (from which RStudio might have drawn some inspiration). SPSS is developed by IBM, so both of these seem like sound solutions for time-series forecasting, but have the disadvantage of being paid.

%TODO:space: expand on R and the ARIMA packges?

\section{Seasonal data}
In what is left of this chapter, I am going to explain each concept that I have used in understanding the ARIMA model and its variations, both in isolation and in relation to the model and its role in choosing the fittest ARIMA model.

I'm going to start with the concept of seasonality, which is an important one for longer time series, like I have here. As a reminder the time-series I'm going to inspect are 150 days long, with 288 observations every day.

Seasonality represents a concept similar to periodicity in mathematics, it's just named differently. In a nutshell it means that the values of a time series will repeat themselves season after season. The mathematical equivalent of this is exhibited in:
\[y_{t+m} \approx y_{t}\]
Where $ t $ is the time when the current observation is acquired and $ m $ is the period. For example if $ m $ is 24 hours, that means that the time series will repeat itself daily, meaning that every hour will be almost the same in regards to the same hour of the last day. For electricity consumption, one could say that the consumption for 12:00 PM will be similar to the demand of the 12th hour of the previous day, and the demand for the evening hour 20:00, will be the same or very similar to the consumption of the last day at 20:00.

Because seasonal patterns tend to be selected from a fixed set, one might try to create a classification of them \cite{hyndmanseasonalperiods}, which can be seen in table \ref{frequentSeasonalPeriods}.

\begin{table}[h]
\begin{tabular}{|c|c|}
    \hline 
    \textbf{Data seasonality} & \textbf{Seasonal period} \\ \hline 
    Annual & 1 \\ \hline 
    Quarterly & 4 \\ \hline 
    Monthly & 12 \\ \hline 
    Weekly & 52 \\ \hline 
\end{tabular} 
\centering
\caption{Frequently used seasonal periods}
\label{frequentSeasonalPeriods}
\end{table}

Data with a smaller seasonal period, such as weekly, daily, hourly, etc., may have multiple periods of interest. One might extract useful prediction patterns from daily data both at a weekly interval and a yearly one. For example in electricity demand prediction one can have daily periodicity in a week as well as monthly periodicity in a year, all for the same data. The patterns of consumption will repeat themselves for each morning, afternoon and evening, but also each month, compared to the previous years' same month, since some patterns occur in winter months and some other patterns occur in summer months. These monthly patterns are inclusive for the daily patterns, both coexist. Examples of such inclusive seasonal patterns are given in table \ref{multipleSeasonalPeriods}, also taken from \cite{hyndmanseasonalperiods}.

\begin{table}[h]
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline 
        \textbf{Data seasonality} & \textbf{Minute} & \textbf{Hour} & \textbf{Day} & \textbf{Week} & \textbf{Year} \\ \hline 
        Daily & & & & 7 & 365.25 \\ \hline 
        Hourly & & & 24 & 168 & 8766 \\ \hline 
        Half-Hourly & & & 48 & 336 & 17532 \\ \hline 
        Minutes & & 60 & 1440 & 10080 & 525960 \\ \hline 
        Seconds & 60 & 3600 & 86400 & 604800 & 31557600 \\ \hline 
    \end{tabular} 
    \centering
    \caption{Higher seasonal periods that may include smaller periods}
    \label{multipleSeasonalPeriods}
\end{table}

For my data, which has been captured every 5 minutes, the seasonal periods are given in table \ref{5minSeasonalPeriods}.

\begin{table}[h]
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline 
        \textbf{Data seasonality} & \textbf{Minute} & \textbf{Hour} & \textbf{Day} & \textbf{Week} & \textbf{Year} \\ \hline 
        5 minute & & 12 & 288 & 2016 & 105192 \\ \hline 
    \end{tabular} 
    \centering
    \caption{Seasonal periods for 5 minute data}
    \label{5minSeasonalPeriods}
\end{table}

Of course this might not always hold true because the value might not be exactly the same, this is one of the reasons I have used the $ \approx $ sign instead of a plain $ = $ in the previous equation. Another reason for using an approximation sign is that the seasonal period may not be exactly $ m $, or 24 hours in my example, since patterns may change with time, for example the lunch break from 12:00 may be shifted forward to 13:00 if the workplace demands it. The same with the evening example, if one has to run errands after work, one may arrive later than 20:00, hence the electrical energy consumption may see the pattern getting shifted. Some of the approximations are also given by the fact that years do not have the same number of days, hence the use of the 365.25 number of days in a year.

In order to capture different seasonal periods of a time series, multiple runs of the ARIMA algorithm are needed, in which the needed seasonality is used. In order to capture multiple seasonal periods at a time one might use Fourier terms. Depending on the number of Fourier terms included in the regression, the seasonal pattern may be smoother (for less terms) or more precise (for many terms). This concept will be further explained in the dedicated section \ref{dynamicharmonicregression}.

The usual way to find a time series' seasonality is to inspect two plots, namely:
\begin{enumerate}
    \item seasonal plot: each data point is plotted against its respective season. An example plot may be seen in figure \ref{exampleseasonalplot}
    \item subseries plot: each season is plotted separately, with data points collected in several mini time series plots. An example of such a plot may be seen in figure \ref{examplesubseriesplot}
\end{enumerate}

As discussed in \cite{fpp2seasonalplot} and \cite{fpp2subseriesplot}, both of the above plots helps the statistician analyze a time series from the point of view of seasonality.
One has to start with inspecting a time plot of the data, in my case electricity consumption on the Y axis against time on the X axis. A time plot of the sub sampled at one hour intervals ph1 time series can be seen in figure \ref{exampletimeplot}. We can see that the plot starts at day 141 in our time series and ends at the beginning of day 148, hence I plotted 7 days worth of data.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{d1hrsph1timeplot.png}
    \caption{Example time plot}
    \label{exampletimeplot}
\end{figure}

The seasonal plot, then takes this data and arranges it in hourly seasons, which is reflected on the X axis, which now has 24 points. This is in accordance with the fact that the data has been down sampled to 1 hour, the reason behind the down sampling being so we can better inspect the plot, by avoiding cluttering it. Because the original time plot contained seven days worth of data, in figure \ref{exampleseasonalplot} there are now seven time series each representing one day, with its respective seasons. The seasonality here becomes obvious in that each day observes an increase in electricity consumption after sunrise, starting with 05:00 in the AM, and ending around 20:00 in the evening.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{d1hrsph1seasonalplot}
    \caption{Example seasonal plot}
    \label{exampleseasonalplot}
\end{figure}

The second type of plot that I'm concerned with is a seasonal sub series plot. Here, again, the original data in split into seasons, so the X axis also shows 24 points, because figure \ref{examplesubseriesplot} is a sub series plot of the same data presented in figure \ref{exampletimeplot}.
This time, though, each season is represented as a mini time series. The first observation of each day is arranged one after the other in the first mini series, then the second hour of each day is arranged in a mini series, and so on, completing all the 24 mini series representing each of the 24 seasons in a day. Because the original time plot had seven days worth of data, each mini time series now consists of seven points. The blue line for each series represents the mean of that series. From this plot, too, one can observe that the energy consumption values are increasing around midday. Hence concluding that we might have a daily seasonality, where electrical energy demand will repeat every 24 hours.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{d1hrsph1subseriesplot}
    \caption{Example subseries plot}
    \label{examplesubseriesplot}
\end{figure}

\subsection{Cyclic data}
The difference between seasonal data and cyclic data is that seasonality manifests itself at fixed intervals, annually, quarterly, monthly, weekly, etc. While cyclic patterns do not exhibit such predictable features, as they are not related to calendar events, but to economic and business conditions. Cyclic patterns exhibit much more volatile properties, the variations between cycles being wider and not as predictable as seasonal variations, which are more stable \cite{fpp2tspatterns}.

%TODO: time-series analysis on wiki

%TODO: https://en.wikipedia.org/wiki/Box%E2%80%93Jenkins_method

%TODO: look in the FPP2 book for ARIMA concepts

%TODO: look at the arima models that I have generated and explain everythign in there, plots and tests

\section{Stationarity and non-stationarity}

\section{Differencing}

\section{Box-Cox transformation}

\section{Seasonal time series}
\subsection{Seasonal differencing}

\section{Autocorrelation function}
The autocorrelation spectrum, image from R. Nau

\subsection{Critical values}

\section{Partial Autocorrelation function}
%TODO: Reiterate the critical vales idea from the previous section

\section{Residuals analysis}
\subsection{QQ plots}
%TODO: more subsections as needed from the Rmd
\subsection{Ljung-Box test}
ARIMA, introduce each concept individually

\section{Information criteria}

\section{Accuracy measures}

\section{The backshift operator}

\section{Dynamic harmonic regression} \label{dynamicharmonicregression}
Fourier

\section{Forecasting with dummies}
Hourly, weekly, "weekend-ly"
+1 error in choosing dummies

\section{The dataset}
The final part of this chapter will give an insight on what the data is and what it looks like.

about the data, present a snippet of it
talk about the 80/20 rule and how we cannot "take random samples out of the data" since we're talking about time series

Say that I have replaced the negative values with zeros.

Say about "down sampling" of data and why is it necessary.



\newpage
\chapter{Practical considerations}
Say something about smart meters

\section{Applied R}
reiterate some R stuff and show some code
R extension
R program structure
\subsection{The forecast package}

particularity: seasonality = frequency \cite{hyndmanseasonalperiods}
\subsection{Benchmark methods in code}
Show meanf, average, naive code.

\subsection{ARIMA in code}
Show some example arima code.
Say about the parallelization and data down sampling.
Say about the "for"-s that I used to search through multiple possibilities.


\section{Methodology}
% TODO: https://en.wikipedia.org/wiki/Box%E2%80%93Jenkins_method
start using my data as the example workflow and reiterating the theory to achieve the complete work-flow

\section{Difficulties in implementation of the methodology}
No difficulty in the theoretical part since it is well established and widely used by now.
But the technical part, parallelization, errors, etc

\section{Results}
%TODO -Which are the main results of your paper and application areas ?

%TODO: tables with results and attached plots


\section{Future work}
%TODO -Which are the main steps to develop your research in the future ?
%TODO: avergage, naive, snaive on embedded
%TODO: errors cause

\section{Conclusions}
%TODO: abstract, introduction, R, data, methodology, ARIMA, results, future work

\newpage
\bibliographystyle{plain}
\bibliography{bibliografie}

\end{document}
